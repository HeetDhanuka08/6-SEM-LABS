{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Name :- Heet Dhanuka\n",
        "\n",
        "Batch :- B2\n",
        "\n",
        "Roll No. :- 34\n",
        "\n",
        "DL practical 6b\n",
        "\n",
        "------\n",
        "\n",
        "Aim :- Design and implement a CNN model for fruit classification, and then apply transfer learning by utilizing at least  two pretrained model like VGG19 and RESNET 50 to achieve the same objective.  "
      ],
      "metadata": {
        "id": "jgfzwFyQxTbI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ddfz-yLKjPt4",
        "outputId": "17a75e7b-7c37-456d-a237-b7e36be0e783"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.11/dist-packages (1.6.17)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.3.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.11/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kaggle) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->kaggle) (3.10)\n",
            "cp: cannot stat 'kaggle.json': No such file or directory\n",
            "chmod: cannot access '/root/.kaggle/kaggle.json': No such file or directory\n",
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.7.4.2 / client 1.6.17)\n",
            "Dataset URL: https://www.kaggle.com/datasets/utkarshsaxenadn/fruits-classification\n",
            "License(s): CC0-1.0\n",
            "Downloading fruits-classification.zip to /content\n",
            " 85% 72.0M/84.8M [00:00<00:00, 202MB/s]\n",
            "100% 84.8M/84.8M [00:00<00:00, 165MB/s]\n",
            "Number of classes: 5\n"
          ]
        }
      ],
      "source": [
        "!pip install kaggle\n",
        "\n",
        "# Download the dataset (replace with your Kaggle API token)\n",
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle datasets download utkarshsaxenadn/fruits-classification\n",
        "\n",
        "# Code to unzip the file\n",
        "import zipfile\n",
        "with zipfile.ZipFile('/content/fruits-classification.zip', 'r') as zip_ref:\n",
        "  zip_ref.extractall('/content')\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "\n",
        "# Define the image dimensions\n",
        "img_width, img_height = 224, 224\n",
        "train_data_dir = '/content/Fruits Classification/train'\n",
        "validation_data_dir = '/content/Fruits Classification/test'\n",
        "nb_train_samples = 41322\n",
        "nb_validation_samples = 13877\n",
        "epochs = 1\n",
        "batch_size = 16\n",
        "\n",
        "import os\n",
        "\n",
        "num_classes = len(os.listdir(train_data_dir))\n",
        "print(f\"Number of classes: {num_classes}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN Model\n",
        "def create_cnn_model():\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(img_width, img_height, 3)))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(128, activation='relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(num_classes , activation='softmax'))  # Assuming 131 classes\n",
        "  return model"
      ],
      "metadata": {
        "id": "8ajh1Y9P0-JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transfer Learning with VGG19\n",
        "def create_vgg19_model():\n",
        "  base_model = VGG19(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))\n",
        "  x = base_model.output\n",
        "  x = GlobalAveragePooling2D()(x)\n",
        "  x = Dense(1024, activation='relu')(x)\n",
        "  predictions = Dense(num_classes, activation='softmax')(x)\n",
        "  model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "  for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "SvWF7BvW1CSp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transfer Learning with ResNet50\n",
        "def create_resnet50_model():\n",
        "  base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))\n",
        "  x = base_model.output\n",
        "  x = GlobalAveragePooling2D()(x)\n",
        "  x = Dense(1024, activation='relu')(x)\n",
        "  predictions = Dense(num_classes, activation='softmax')(x)\n",
        "  model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "  for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "Xt0rTZtZ1Gqr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Augmentation and Generators\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1. / 255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "training_set = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical')\n",
        "\n",
        "test_set = test_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ch5pwhB11NNa",
        "outputId": "32f294c6-1691-4713-d28b-f537b97ba48a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 9700 images belonging to 5 classes.\n",
            "Found 100 images belonging to 5 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the models\n",
        "def train_model(model, model_name):\n",
        "  model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  model.fit(\n",
        "      training_set,\n",
        "      steps_per_epoch=nb_train_samples // batch_size,\n",
        "      epochs=epochs,\n",
        "      validation_data=test_set,\n",
        "      validation_steps=nb_validation_samples // batch_size)\n",
        "\n",
        "  model.save(f\"{model_name}.h5\")\n",
        "  print(f\"{model_name} model trained and saved.\")\n",
        "\n",
        "\n",
        "# Create and train CNN\n",
        "cnn_model = create_cnn_model()\n",
        "train_model(cnn_model, \"cnn_model\")\n",
        "\n",
        "# Create and train VGG19\n",
        "vgg19_model = create_vgg19_model()\n",
        "train_model(vgg19_model, \"vgg19_model\")\n",
        "\n",
        "# Create and train ResNet50\n",
        "resnet50_model = create_resnet50_model()\n",
        "train_model(resnet50_model, \"resnet50_model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-fSUnLF1QFy",
        "outputId": "53dcf97b-4dcf-4dab-ac62-4f517509f9a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m 607/2582\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:24\u001b[0m 225ms/step - accuracy: 0.3502 - loss: 1.4531"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:107: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 54ms/step - accuracy: 0.4065 - loss: 1.3584 - val_accuracy: 0.5300 - val_loss: 1.1498\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cnn_model model trained and saved.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m80134624/80134624\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 59ms/step - accuracy: 0.5110 - loss: 1.2889 - val_accuracy: 0.6200 - val_loss: 0.9830\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vgg19_model model trained and saved.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "\u001b[1m2582/2582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 55ms/step - accuracy: 0.2567 - loss: 1.5953 - val_accuracy: 0.3200 - val_loss: 1.5798\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "resnet50_model model trained and saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-PByXGhsyyvc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}